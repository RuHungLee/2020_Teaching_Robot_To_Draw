{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 516\n",
      "current 0\n",
      "total 516\n",
      "current 38\n",
      "total 516\n",
      "current 90\n",
      "total 516\n",
      "current 107\n",
      "total 516\n",
      "current 124\n",
      "total 516\n",
      "current 156\n",
      "total 516\n",
      "current 234\n",
      "total 516\n",
      "current 295\n",
      "total 516\n",
      "current 353\n",
      "total 516\n",
      "current 385\n",
      "total 516\n",
      "current 470\n",
      "saving fig file\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor , ToPILImage , ToPILImage\n",
    "from lmodel import Local\n",
    "from gmodel import Global\n",
    "\n",
    "Lpretrained = './pretrained/2_run.pth.tar'\n",
    "Lmodel = Local()\n",
    "Lmodel.load_state_dict(torch.load(Lpretrained , map_location=torch.device('cpu')))\n",
    "\n",
    "Gpretrained = './pretrained/5_run.pth.tar'\n",
    "Gmodel = Global()\n",
    "Gmodel.load_state_dict(torch.load(Gpretrained , map_location=torch.device('cpu')))\n",
    "\n",
    "path = './test/test2.jpg'\n",
    "\n",
    "#np.set_printoptions(threshold = np.inf)\n",
    "def dfs(seen , img , img_connected , x , y):\n",
    "    for i in [-2 , -1 , 0 , 1 , 2]:\n",
    "        for j in [-2 , -1 , 0 , 1 , 2]:\n",
    "            if (i,j)!=(0,0):\n",
    "                nx = x + i\n",
    "                ny = y + j\n",
    "                if(not (nx>0 and nx<109 and ny>0 and ny<109)):\n",
    "                    continue\n",
    "                if(img[nx][ny]!=0 and (nx,ny) not in seen):\n",
    "                    seen.append((nx , ny))\n",
    "                    dfs(seen , img , img_connected , nx , ny)\n",
    "                    img_connected[nx,ny] = 1\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    to_tensor = ToTensor()\n",
    "    to_pil = ToPILImage()\n",
    "    imgin = np.array(Image.open(path))\n",
    "    imgin = np.where(imgin<100 , 0 , 255)\n",
    "    img = to_tensor(Image.open(path)).float()\n",
    "    v = to_tensor(np.zeros((109 , 109 , 1))).float()\n",
    "    le = to_tensor(np.zeros((109 , 109 ,1))).float()\n",
    "    ls = to_tensor(np.zeros((109 , 109 , 1))).float()\n",
    "    uv = img\n",
    "    id = 0\n",
    "\n",
    "    #total point \n",
    "    cnt = 0\n",
    "    for i in range(109):\n",
    "        for j in range(109):\n",
    "            if(imgin[i][j]==255):\n",
    "                cnt += 1\n",
    "    \n",
    "    image_list = list()    \n",
    "    \n",
    "    while(1):    \n",
    "        \n",
    "        #break situation\n",
    "        p = 0\n",
    "        for i in range(109):\n",
    "            for j in range(109):\n",
    "                if v[0,i,j]>0.5:\n",
    "                    p += 1\n",
    "        if(cnt-p<5):\n",
    "            break\n",
    "        print('total' , cnt)\n",
    "        print('current' , p)\n",
    "\n",
    "        gx = torch.cat((v , uv , le , ls) , 0)\n",
    "        gx = torch.unsqueeze(gx , 0)\n",
    "\n",
    "        #Global model\n",
    "        gx = gx\n",
    "        locate = Gmodel(gx)\n",
    "        locate = torch.max(locate.view(locate.shape[0] , -1) , 1)[1]\n",
    "        locate_x = locate/109\n",
    "        locate_y = locate%109\n",
    "\n",
    "        #Local model \n",
    "        v[0 , locate_x , locate_y ] = 1\n",
    "        uv[0 , locate_x , locate_y] = 0\n",
    "        seen = []\n",
    "        img_c = torch.zeros((109 , 109))\n",
    "        connected = dfs(seen , imgin , img_c , locate_x , locate_y)\n",
    "        img_c = torch.unsqueeze(img_c ,0).float()\n",
    "        head = (locate_x , locate_y)\n",
    "        x = torch.cat((v , uv , img_c) , 0)\n",
    "        image = to_pil(img_c)\n",
    "        x = torch.unsqueeze(x , 0)\n",
    "        touched = 0\n",
    "\n",
    "        #clear ls and le \n",
    "        le = to_tensor(np.zeros((109 , 109 ,1))).float()\n",
    "        ls = to_tensor(np.zeros((109 , 109 , 1))).float()\n",
    "\n",
    "        while(touched < 0.5):\n",
    "            touched , shifted = Lmodel(x , head)\n",
    "            shifted = torch.max(shifted , 1)[1]\n",
    "            shifted_x = (shifted)/5-2\n",
    "            shifted_y = (shifted)%5-2\n",
    "            #avoid infinity loop\n",
    "            if shifted_x==0 and shifted_y==0:\n",
    "                break\n",
    "            nx = head[0]+shifted_x\n",
    "            ny = head[1]+shifted_y\n",
    "            v[0,nx,ny] = 1\n",
    "            uv[0,nx,ny] = 0\n",
    "            head = (nx , ny)\n",
    "            ls[0,nx,ny] = 1\n",
    "            x = torch.cat((v , uv , img_c) , 0)\n",
    "            x = torch.unsqueeze(x , 0)\n",
    "            image_list.append(to_pil(v.cpu().clone()))\n",
    "        le[0,nx,ny] = 1\n",
    "        id += 1\n",
    "        first = False\n",
    "    \n",
    "    #gif\n",
    "    print('saving fig file')\n",
    "    image_list[0].save('./out4.gif' , save_all = True , append_images = image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
